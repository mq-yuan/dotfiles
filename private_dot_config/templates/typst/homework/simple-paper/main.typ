#import "simplepaper.typ": *

#show: project.with(
  title: "底层视觉-522024710016-袁萌启",
  authors: (
    (
      name: "袁萌启",
      id: "522024710016",
      email: "mqyuan@smail.nju.edu.cn"
    ),
  ),
)
#show figure.caption: it => {
  set align(left)
  set text(size: 9pt)
  it
}
#let indent = h(2em)

= 论文介绍

我选取了 "RePaint: Inpainting using Denoising Diffusion Probabilistic Models" 这个论文，发表于 2022 CVPR。
作者列表为 "Andreas Lugmayr Martin Danelljan Andres Romero Fisher Yu Radu Timofte Luc Van Gool"

目前位置该论文的官方 #link("https://github.com/andreas128/RePaint")[github] 仓库已有 2.1k star，在 google scholar 上截止到 #datetime.today().display() 为止有 1986 次引用，符合我们的课程要求。

本文件，@cap:2 是论文翻译.

= 论文翻译<cap:2>
Repaint：使用去噪扩散概率模型的图像修复 

== 摘要

自由形式图像修复是指在由任意 binary mask 指定的图像区域中添加新内容的任务。
大多数现有方法都针对特定 distribution of masks 进行训练，这限制了它们对 unseen mask types 的泛化能力。
此外，使用像素级和感知损失进行训练通常会导致使用简单的 texture extensions 来补全缺失区域，而不是语义上有意义的生成。
在这项工作中，我们提出了 RePaint：一种基于 DDPM 的图像修复方法，该方法甚至适用于极端的 mask。
我们采用 a pretrained unconditional DDPM 作为生成先验。
为了调节生成过程，我们仅通过使用给定图像信息对 unmasked region 进行采样来改变反向扩散迭代。
由于该技术不会修改或调节原始 DDPM 网络本身，因此该模型可以为任何修复形式生成高质量和多样化的输出图像。
我们使用 standard and extreme masks 验证了我们的方法在面部和通用图像修复方面的性能。
对于六个 mask 分布中的至少五个，RePaint 优于最先进的自回归和 GAN 方法。Github 仓库：#link("https://github.com/andreas128/RePaint")[git.io/RePaint]

== Introduction


图像修复，又称图像补全，旨在填充图像中的缺失区域。这些修复后的区域需要与图像的其余部分协调一致。
因此，图像修复方法需要强大的生成能力。为此，当前最先进的方法依赖于 GANs 或自回归建模。此外，图像修复方法需要处理各种形式的 mask ，例如细笔刷或粗笔刷、方形，甚至图像绝大部分缺失的极端 mask 。
这极具挑战性，因为现有方法使用某种 mask 分布进行训练，这可能导致对新型 mask 类型的泛化能力差。
在这项工作中，我们研究了一种替代的图像修复生成方法，旨在设计一种不需要特定 mask 训练的方法。 

DDPM 是一种新兴的生成建模替代范式。
最近，Dhariwal 和 Nichol 证明 DDPM 甚至在图像合成方面超越了最先进的基于 GAN 的方法。
本质上，DDPM 通过逆转扩散过程，被训练用于迭代地对图像进行去噪。
从随机采样的噪声开始，DDPM 随后被迭代应用一定数量的步骤，从而得到最终的图像样本。
尽管建立在原则性的概率建模基础上，DDPMs 已被证明能够生成多样化且高质量的图像。

我们提出 RePaint：一种仅利用现成的、无条件训练的 DDPM 的图像修复方法。
具体来说，我们没有学习一个 mask 条件生成模型，而是通过在逆向扩散迭代过程中从给定像素中采样来调节生成过程。
值得注意的是，因此我们的模型并未专门针对图像修复任务本身进行训练。
这带来了两个重要的优势。首先，它使我们的网络能够在推理过程中泛化到任何 mask 。
其次， 由于它拥有强大的 DDPM 图像合成先验，因此它使我们的网络能够学习更具语义的生成能力（@fig:fig1）。

#figure(
  image("images/logo_nju.png", width: 100%),
  caption: [
  我们使用 DDPM 进行图像修复。该过程以 mask 输入 (left) 为条件。
  它从一个随机高斯噪声样本开始，该样本被迭代去噪，直到产生高质量的输出。
  由于此过程是随机的，我们可以采样多个多样化的输出。
  DDPM 先验促使图像协调一致，能够再现其他区域的纹理，并修复语义上有意义的内容.
  ]
)<fig:fig1>

#indent 尽管标准的 DDPM 采样策略能够产生匹配的纹理，但图像修复结果在语义上往往是错误的。
因此，我们 引入了一种改进的去噪策略，该策略通过 resamples (RePaint) 迭代来更好地对图像进行条件化。
值得注意的是，我们的方法并没有像 Nichol 那样减慢扩散过程，而是沿着扩散时间向前和向后进行，从而生成了显著的语义上有意义的图像。
我们的方法使得网络能够在整个推理过程中有效地协调生成的图像信息，从而对给定的图像信息进行更有效的条件化。

我们在 CelebA-HQ 和 ImageNet 上进行了实验，并与其他的最先进的图像修复方法进行了比较。
我们的方法具有更好的泛化能力，并且总体上生成了语义上更合理的修复区域。

== Method

在本节中，我们首先在 @cap:4.1 中介绍我们用于调节无条件 DDPM 的反向扩散过程以进行图像修复的方法。
然后，我们在 @cap:4.2 中介绍一种改进反向过程本身以进行修复的方法。

#figure(
  image("images/logo_nju.png", width: 80%),
  caption: [方法概述。RePaint 修改了标准的去噪过程，以便根据给定的图像内容进行条件化。在每一步中，我们从输入中采样已知区域(top)，并从DDPM输出中采样修复部分(bottom)。]
)<fig:fig2>

=== 已知区域的条件化<cap:4.1>

图像修复的目标是使用 mask 区域作为条件来预测图像中缺失的像素。
在本文的其余部分，我们考虑一个训练好的无条件去噪扩散概率模型。
我们将真实图像表示为 $x$，将未知像素表示为 $m dot.circle x$，将已知像素表示为 $(1 − m) dot.circle x$。

鉴于从 $x_t$ 到 $x_(t−1)$ 的每个反向步骤仅取决于 xt，我们可以改变已知区域 $(1 − m) dot.circle x$，只要我们保持相应分布的正确属性。
由于前向过程是由添加高斯噪声的马尔可夫链定义的，我们可以在任何时间点采样中间图像 $x_t$。
这使得我们能够在任何时间步 $t$ 采样已知区域 $m dot.circle x_t$。
因此，对未知区域使用，对已知区域使用，我们得到了我们方法中一个反向步骤的以下表达式：

$
x_(t-1)^("known") ~ cal(N)(sqrt(macron(alpha)) x_0, (1- macron(alpha)_t))bold(I)\
x_(t-1)^("unknown") ~ cal(N)(mu_(theta) (x_t, t), sum_(theta) (x_t, t))\
x_(t-1) = m dot.circle x_(t-1)^("known") + (1 - m) dot.circle x_(t-1)^("unknown")
$<eq:8>

因此, $x_(t-1)^"known"$ 使用给定图像 $m dot.circle x_0$ 中已知像素进行采样，而 $x_(t-1)^("unknown")$ 则根据前一次迭代 $x_t$ 从模型中进行采样。
然后使用 mask 将它们结合，得到新的样本 $x_(t-1)$。我们的方法在 @fig:fig2 中进行了说明。

=== 重采样<cap:4.2>


当直接应用 @cap:4.1 中描述的方法时，我们观察到只有内容类型与已知区域匹配。
例如，在 @fig:fig3 的 $n = 1$ 中，修复区域是一种毛茸茸的纹理，与狗的毛发匹配。
尽管修复区域与相邻区域的纹理匹配，但它在语义上是错误的。
因此，DDPM 正在利用已知区域的上下文，但它未能与图像的其余部分很好地协调。
接下来，我们将讨论造成这种行为的可能原因。

从 @fig:fig2 中，我们分析了该方法如何对已知区域进行条件化。
如所示，模型使用 $x_t$ 预测 $x_(t-1)$，其中 $x_t$ 包含 DDPM 的输出和来自已知区域的样本。
然而，使用对已知像素进行采样时，没有考虑图像的生成部分，这引入了不协调。
尽管模型在每一步都试图再次协调图像，但它永远无法完全收敛，因为同样的问题会在下一步中发生。
此外，在每个反向步骤中，由于 $beta_t$ 的方差调度，图像的最大变化量会下降。
因此，由于灵活性受限，该方法无法纠正在后续步骤中导致不协调边界的错误。
结果是，模型需要更多时间在一个步骤中协调条件信息 $x_(t-1)^"known"$ 与生成信息 $x_(t-1)^"unknown"$，然后才能进入下一个去噪步骤。

由于 DDPM 被训练用于生成位于数据分布内的图像，它自然地旨在生成一致的结构。
在我们的重采样方法中，我们利用了 DDPM 的这一特性来协调模型的输入。
因此，我们通过从中采样，得到 $x_t ~ cal(N)(sqrt(1 - beta_t x_(t-1)), beta_t bold(I))$，将输出 $x_(t-1)$ 扩散回 $x_t$。
尽管此操作缩减了输出并增加了噪声，在生成的区域 $x_(t-1)^"unknown"$ 中包含的一些信息仍然保留在 $x_t^"unknown"$ 中。
这导致了一个新的 $x_t^"unknown"$，它既与 $x_t^"known"$ 更协调，又包含来自它的条件信息。

由于此操作只能协调一步，它可能无法在整个去噪过程中整合语义信息。
为了克服这个问题，我们将此操作的时间范围表示为跳跃长度，在前一种情况下为 $j = 1$。
类似于扩散速度的标准变化（a.k.a. 减速），重采样也增加了逆向扩散的运行时间。
减速通过减少每个去噪步骤中添加的方差来应用更小但更多的重采样步骤。
然而，这是一种根本不同的方法，因为减慢扩散仍然存在无法协调图像的问题，正如我们的重采样策略中所述。
我们在第 5.6 节中经验性地证明了我们方法的这一优势。

#figure(
  image("./images/logo_nju.png", width: 100%),
  caption: [应用n采样步骤的效果。第一个示例，其中n = 1是DDPM基线，第二个示例，其中n = 2是包含一个重采样步骤。更多的 重采样步骤会使图像更加协调。这种益处在大约n = 10次重采样后达到饱和。 ]
)<fig:fig3>

